{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1.5: Prepare GSPO Dataset\n",
    "\n",
    "This notebook transforms the improved Norwegian Alpaca dataset (from Phase 1) into a GSPO-ready format for alignment training.\n",
    "\n",
    "**What this adds:**\n",
    "- `prompt` — Chat-formatted prompt (`[{\"role\": \"user\", \"content\": ...}]`) compatible with TRL's `GRPOTrainer` and Qwen3.5's chat template\n",
    "- `task_type` — Heuristic classification of each instruction (qa, generation, classification, extraction, rewriting, creative, other) used for task-specific reward routing\n",
    "\n",
    "**Input:** `norwegian_alpaca_improved.parquet` (from Phase 1)\n",
    "**Output:** `norwegian_alpaca_gspo.parquet` (ready for Phase 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library (editable mode)\n",
    "# On Colab, clone the repo first:\n",
    "#   !git clone https://github.com/your-username/NORAI-Tools.git /content/NORAI-Tools\n",
    "#   %pip install -e /content/NORAI-Tools\n",
    "\n",
    "%pip install -e ..\n",
    "\n",
    "from norai_tools import (\n",
    "    prepare_gspo_dataset,\n",
    "    validate_gspo_dataset,\n",
    "    classify_task_type,\n",
    "    OUTPUT_FILE,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Configuration + load improved dataset from Phase 1\n",
    "# ============================================================\n",
    "\n",
    "IMPROVED_DATASET_PATH = OUTPUT_FILE  # \"norwegian_alpaca_improved.parquet\"\n",
    "GSPO_OUTPUT_PATH = \"norwegian_alpaca_gspo.parquet\"\n",
    "\n",
    "# Optional: HuggingFace Hub push\n",
    "PUSH_TO_HUB = False\n",
    "HUB_REPO_ID = \"your-username/norwegian-alpaca-gspo\"  # Change this\n",
    "\n",
    "dataset = load_dataset(\"parquet\", data_files=IMPROVED_DATASET_PATH, split=\"train\")\n",
    "\n",
    "print(f\"Loaded: {len(dataset)} rows\")\n",
    "print(f\"Columns: {dataset.column_names}\")\n",
    "\n",
    "# Verify required columns from Phase 1\n",
    "required = [\"instruction_improved\", \"input_improved\", \"output_improved\", \"instruction_en\"]\n",
    "missing = [c for c in required if c not in dataset.column_names]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns from Phase 1: {missing}\")\n",
    "print(\"All required columns present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Prepare GSPO dataset (add prompt + task_type columns)\n",
    "# ============================================================\n",
    "\n",
    "gspo_dataset = prepare_gspo_dataset(dataset)\n",
    "\n",
    "print(f\"GSPO dataset: {len(gspo_dataset)} rows\")\n",
    "print(f\"Columns: {gspo_dataset.column_names}\")\n",
    "print(f\"\\nSample prompt (row 0):\")\n",
    "print(gspo_dataset[0][\"prompt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Validate the GSPO dataset\n",
    "# ============================================================\n",
    "\n",
    "validation = validate_gspo_dataset(gspo_dataset)\n",
    "\n",
    "print(f\"Total rows:      {validation['total_rows']}\")\n",
    "print(f\"Empty prompts:   {validation['empty_prompts']}\")\n",
    "print(f\"Missing columns: {validation['missing_columns']}\")\n",
    "print(f\"Valid:           {validation['is_valid']}\")\n",
    "\n",
    "if not validation[\"is_valid\"]:\n",
    "    print(\"\\nWARNING: Dataset failed validation. Check issues above before proceeding.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Inspect task_type distribution + sample prompts\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dist = validation[\"task_type_distribution\"]\n",
    "sorted_dist = dict(sorted(dist.items(), key=lambda x: -x[1]))\n",
    "\n",
    "print(\"Task type distribution:\")\n",
    "for task, count in sorted_dist.items():\n",
    "    print(f\"  {task:20s}: {count:6d} ({100*count/len(gspo_dataset):.1f}%)\")\n",
    "\n",
    "# Bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "ax.barh(list(sorted_dist.keys()), list(sorted_dist.values()))\n",
    "ax.set_xlabel(\"Count\")\n",
    "ax.set_title(\"Task Type Distribution\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show sample prompts per task type\n",
    "print(\"\\nSample prompts by task type:\")\n",
    "shown = set()\n",
    "for row in gspo_dataset:\n",
    "    task = row[\"task_type\"]\n",
    "    if task not in shown:\n",
    "        shown.add(task)\n",
    "        content = row[\"prompt\"][0][\"content\"][:120]\n",
    "        print(f\"  [{task}] {content}...\")\n",
    "    if len(shown) == len(sorted_dist):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Save to parquet + optional Hub push\n",
    "# ============================================================\n",
    "\n",
    "gspo_dataset.to_parquet(GSPO_OUTPUT_PATH)\n",
    "print(f\"Saved GSPO dataset to: {GSPO_OUTPUT_PATH}\")\n",
    "print(f\"  Rows: {len(gspo_dataset)}\")\n",
    "print(f\"  Columns: {gspo_dataset.column_names}\")\n",
    "\n",
    "if PUSH_TO_HUB:\n",
    "    gspo_dataset.push_to_hub(HUB_REPO_ID, private=True)\n",
    "    print(f\"Pushed to Hub: {HUB_REPO_ID}\")\n",
    "else:\n",
    "    print(\"\\nSet PUSH_TO_HUB = True and update HUB_REPO_ID to push to the Hub.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
